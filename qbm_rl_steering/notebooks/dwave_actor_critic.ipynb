{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/michael/Desktop/orig/qbm-rl-steering/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! Cannot import libraries required for QAOA ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import datetime\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay, PiecewiseConstantDecay\n",
    "from qbm_rl_steering.core.ddpg_agents import ClassicalDDPG, QuantumDDPG\n",
    "from qbm_rl_steering.environment.rms_env_nd import RmsSteeringEnv\n",
    "from qbm_rl_steering.environment.orig_awake_env import e_trajectory_simENV\n",
    "from qbm_rl_steering.core.run_utils import trainer, evaluator, plot_training_log, plot_evaluation_log\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No additional exploration when reloading agents to continue training\n",
    "# Not sure what to do with the learning rate schedules, action noise and epsilon exploration...\n",
    "# Maybe start from slightly lower ... a bit strange potentially.\n",
    "params = {\n",
    "    'quantum_ddpg': True,\n",
    "    'n_steps': 440,\n",
    "    'env/max_steps_per_episode': 8,\n",
    "    'env/required_steps_above_reward_threshold': 1,\n",
    "    'trainer/batch_size': 16,\n",
    "    'trainer/n_exploration_steps': 400,\n",
    "    'trainer/n_episodes_early_stopping': 20000,\n",
    "    'agent/gamma': 0.97,\n",
    "    'agent/tau_critic': 0.00013,\n",
    "    'agent/tau_actor': 0.0005,\n",
    "    'lr_critic/init': 0.00025,\n",
    "    'lr_critic/decay_factor': 1.,\n",
    "    'lr_actor/init': 0.00032,\n",
    "    'lr_actor/decay_factor': 1., \n",
    "    'lr/final': 5e-5,\n",
    "    'action_noise/init': 0.3,\n",
    "    'action_noise/final': 0.,\n",
    "    'epsilon_greedy/init': 0.5,\n",
    "    'epsilon_greedy/final': 0., \n",
    "    'anneals/n_pieces': 2,\n",
    "    'anneals/init': 1,\n",
    "    'anneals/final': 1,  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/Desktop/orig/qbm-rl-steering/qbm_rl_steering/environment/utils/twissReader.py:247: UserWarning: MISSING FIELD PX IN TWISS INPUT /Users/michael/Desktop/qbm-rl-steering/qbm_rl_steering/environment/utils/electron_tt43.out\n",
      "  warnings.warn('MISSING FIELD ' + FIELD_PX + ' IN TWISS INPUT ' + inputFile)\n",
      "/Users/michael/Desktop/orig/qbm-rl-steering/qbm_rl_steering/environment/utils/twissReader.py:262: UserWarning: MISSING FIELD PY IN TWISS INPUT/Users/michael/Desktop/qbm-rl-steering/qbm_rl_steering/environment/utils/electron_tt43.out\n",
      "  warnings.warn('MISSING FIELD ' + FIELD_PY + ' IN TWISS INPUT' + inputFile)\n",
      "/Users/michael/miniconda3/envs/dwaveenv/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "env = e_trajectory_simENV()\n",
    "\n",
    "# Learning rate schedules\n",
    "lr_schedule_critic = PolynomialDecay(\n",
    "    params['lr_critic/init'], params['n_steps'],\n",
    "    end_learning_rate=params['lr/final'])\n",
    "lr_schedule_actor = PolynomialDecay(\n",
    "    params['lr_actor/init'], params['n_steps'],\n",
    "    end_learning_rate=params['lr/final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 16:25:11.464982: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SETTING PROPER QPU AS SAMPLER\n",
      "QPU Advantage_system6.1 was selected.\n",
      " ! Warning: big_gammas are 'virtual'. We don't know the actual values ... \n",
      "SETTING PROPER QPU AS SAMPLER\n",
      "QPU Advantage_system6.1 was selected.\n",
      " ! Warning: big_gammas are 'virtual'. We don't know the actual values ... \n"
     ]
    }
   ],
   "source": [
    "if params['quantum_ddpg']:\n",
    "    agentMy = QuantumDDPG(\n",
    "        state_space=env.observation_space,\n",
    "        action_space=env.action_space,\n",
    "        learning_rate_schedule_critic=lr_schedule_critic,\n",
    "        learning_rate_schedule_actor=lr_schedule_actor,\n",
    "        grad_clip_actor=np.inf, grad_clip_critic=np.inf,\n",
    "        gamma=params['agent/gamma'],\n",
    "        tau_critic=params['agent/tau_critic'],\n",
    "        tau_actor=params['agent/tau_actor'],\n",
    "    )\n",
    "else:\n",
    "    agentMy = ClassicalDDPG(\n",
    "        state_space=env.observation_space,\n",
    "        action_space=env.action_space,\n",
    "        learning_rate_critic=params['lr_critic/init'],\n",
    "        learning_rate_actor=params['lr_actor/init'],\n",
    "        grad_clip_actor=np.inf, grad_clip_critic=np.inf,\n",
    "        gamma=params['agent/gamma'],\n",
    "        tau_critic=params['agent/tau_critic'],\n",
    "        tau_actor=params['agent/tau_actor'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action noise schedule\n",
    "action_noise_schedule = PolynomialDecay(\n",
    "    params['action_noise/init'], params['n_steps'],\n",
    "    params['action_noise/final'])\n",
    "\n",
    "# Epsilon greedy schedule\n",
    "epsilon_greedy_schedule = PolynomialDecay(\n",
    "    params['epsilon_greedy/init'], params['n_steps'],\n",
    "    params['epsilon_greedy/final'])\n",
    "\n",
    "# Schedule n_anneals\n",
    "t_transition = [int(x * params['n_steps']) for x in\n",
    "                np.linspace(0, 1., params['anneals/n_pieces'] + 1)][1:-1]\n",
    "y_transition = [int(n) for n in np.linspace(params['anneals/init'],\n",
    "                                            params['anneals/final'],\n",
    "                                            params['anneals/n_pieces'])]\n",
    "n_anneals_schedule = PiecewiseConstantDecay(t_transition, y_transition)\n",
    "\n",
    "# PREPARE OUTPUT FOLDERs\n",
    "date_time_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "out_path = './runs/indiv/' + date_time_now\n",
    "os.makedirs(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE: 0\n",
      "INITIAL REWARD: -162.804\n",
      "FINAL REWARD: -394.858\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -394.858\n",
      "MOVING AVG #STEPS: 8.0\n",
      "\n",
      "EPISODE: 1\n",
      "INITIAL REWARD: -245.548\n",
      "FINAL REWARD: -511.288\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -453.073\n",
      "MOVING AVG #STEPS: 8.0\n",
      "\n",
      "EPISODE: 2\n",
      "INITIAL REWARD: -286.527\n",
      "FINAL REWARD: -524.608\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -476.918\n",
      "MOVING AVG #STEPS: 8.0\n",
      "\n",
      "EPISODE: 3\n",
      "INITIAL REWARD: -137.536\n",
      "FINAL REWARD: -33.357\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -366.028\n",
      "MOVING AVG #STEPS: 6.2\n",
      "\n",
      "EPISODE: 4\n",
      "INITIAL REWARD: -224.418\n",
      "FINAL REWARD: -77.625\n",
      "#STEPS: 3 (3 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -308.347\n",
      "MOVING AVG #STEPS: 5.6\n",
      "\n",
      "EPISODE: 5\n",
      "INITIAL REWARD: -258.905\n",
      "FINAL REWARD: -1479.27\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -503.501\n",
      "MOVING AVG #STEPS: 6.0\n",
      "\n",
      "EPISODE: 6\n",
      "INITIAL REWARD: -229.334\n",
      "FINAL REWARD: -22.568\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -434.796\n",
      "MOVING AVG #STEPS: 5.3\n",
      "\n",
      "EPISODE: 7\n",
      "INITIAL REWARD: -206.237\n",
      "FINAL REWARD: -1031.686\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -509.408\n",
      "MOVING AVG #STEPS: 5.6\n",
      "\n",
      "EPISODE: 8\n",
      "INITIAL REWARD: -327.432\n",
      "FINAL REWARD: -744.137\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -535.489\n",
      "MOVING AVG #STEPS: 5.9\n",
      "\n",
      "EPISODE: 9\n",
      "INITIAL REWARD: -169.279\n",
      "FINAL REWARD: -113.868\n",
      "#STEPS: 6 (6 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -493.327\n",
      "MOVING AVG #STEPS: 5.9\n",
      "\n",
      "EPISODE: 10\n",
      "INITIAL REWARD: -201.135\n",
      "FINAL REWARD: -32.548\n",
      "#STEPS: 7 (7 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -451.438\n",
      "MOVING AVG #STEPS: 6.0\n",
      "\n",
      "EPISODE: 11\n",
      "INITIAL REWARD: -343.934\n",
      "FINAL REWARD: -104.584\n",
      "#STEPS: 4 (4 RANDOM)\n",
      "EARLY STOPPING COUNT: 3/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -422.533\n",
      "MOVING AVG #STEPS: 5.8\n",
      "\n",
      "EPISODE: 12\n",
      "INITIAL REWARD: -136.386\n",
      "FINAL REWARD: -641.465\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -439.374\n",
      "MOVING AVG #STEPS: 6.0\n",
      "\n",
      "EPISODE: 13\n",
      "INITIAL REWARD: -241.061\n",
      "FINAL REWARD: -105.445\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -415.522\n",
      "MOVING AVG #STEPS: 5.6\n",
      "\n",
      "EPISODE: 14\n",
      "INITIAL REWARD: -132.889\n",
      "FINAL REWARD: -313.826\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -408.742\n",
      "MOVING AVG #STEPS: 5.8\n",
      "\n",
      "EPISODE: 15\n",
      "INITIAL REWARD: -159.156\n",
      "FINAL REWARD: -18.379\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -384.344\n",
      "MOVING AVG #STEPS: 5.5\n",
      "\n",
      "EPISODE: 16\n",
      "INITIAL REWARD: -134.376\n",
      "FINAL REWARD: -11.407\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -362.407\n",
      "MOVING AVG #STEPS: 5.2\n",
      "\n",
      "EPISODE: 17\n",
      "INITIAL REWARD: -355.164\n",
      "FINAL REWARD: -509.995\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -370.606\n",
      "MOVING AVG #STEPS: 5.4\n",
      "\n",
      "EPISODE: 18\n",
      "INITIAL REWARD: -133.732\n",
      "FINAL REWARD: -67.194\n",
      "#STEPS: 3 (3 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -354.637\n",
      "MOVING AVG #STEPS: 5.3\n",
      "\n",
      "EPISODE: 19\n",
      "INITIAL REWARD: -194.715\n",
      "FINAL REWARD: -608.477\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -367.329\n",
      "MOVING AVG #STEPS: 5.4\n",
      "\n",
      "EPISODE: 20\n",
      "INITIAL REWARD: -183.183\n",
      "FINAL REWARD: -151.331\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -357.044\n",
      "MOVING AVG #STEPS: 5.5\n",
      "\n",
      "EPISODE: 21\n",
      "INITIAL REWARD: -175.223\n",
      "FINAL REWARD: -36.017\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -342.451\n",
      "MOVING AVG #STEPS: 5.3\n",
      "\n",
      "EPISODE: 22\n",
      "INITIAL REWARD: -142.492\n",
      "FINAL REWARD: -109.858\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -332.339\n",
      "MOVING AVG #STEPS: 5.1\n",
      "\n",
      "EPISODE: 23\n",
      "INITIAL REWARD: -295.509\n",
      "FINAL REWARD: -86.356\n",
      "#STEPS: 6 (6 RANDOM)\n",
      "EARLY STOPPING COUNT: 3/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -322.089\n",
      "MOVING AVG #STEPS: 5.2\n",
      "\n",
      "EPISODE: 24\n",
      "INITIAL REWARD: -163.23\n",
      "FINAL REWARD: -327.791\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -322.317\n",
      "MOVING AVG #STEPS: 5.3\n",
      "\n",
      "EPISODE: 25\n",
      "INITIAL REWARD: -124.037\n",
      "FINAL REWARD: -368.753\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -324.103\n",
      "MOVING AVG #STEPS: 5.4\n",
      "\n",
      "EPISODE: 26\n",
      "INITIAL REWARD: -250.457\n",
      "FINAL REWARD: -615.196\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -334.885\n",
      "MOVING AVG #STEPS: 5.5\n",
      "\n",
      "EPISODE: 27\n",
      "INITIAL REWARD: -173.009\n",
      "FINAL REWARD: -71.577\n",
      "#STEPS: 6 (6 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -325.481\n",
      "MOVING AVG #STEPS: 5.5\n",
      "\n",
      "EPISODE: 28\n",
      "INITIAL REWARD: -345.382\n",
      "FINAL REWARD: -808.335\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -342.131\n",
      "MOVING AVG #STEPS: 5.6\n",
      "\n",
      "EPISODE: 29\n",
      "INITIAL REWARD: -149.631\n",
      "FINAL REWARD: -69.141\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -333.031\n",
      "MOVING AVG #STEPS: 5.4\n",
      "\n",
      "EPISODE: 30\n",
      "INITIAL REWARD: -178.283\n",
      "FINAL REWARD: -58.185\n",
      "#STEPS: 4 (4 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -321.809\n",
      "MOVING AVG #STEPS: 5.3\n",
      "\n",
      "EPISODE: 31\n",
      "INITIAL REWARD: -262.302\n",
      "FINAL REWARD: -115.355\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 3/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -308.611\n",
      "MOVING AVG #STEPS: 5.1\n",
      "\n",
      "EPISODE: 32\n",
      "INITIAL REWARD: -347.172\n",
      "FINAL REWARD: -107.191\n",
      "#STEPS: 7 (7 RANDOM)\n",
      "EARLY STOPPING COUNT: 4/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -294.697\n",
      "MOVING AVG #STEPS: 5.0\n",
      "\n",
      "EPISODE: 33\n",
      "INITIAL REWARD: -184.663\n",
      "FINAL REWARD: -52.509\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 5/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -295.336\n",
      "MOVING AVG #STEPS: 5.0\n",
      "\n",
      "EPISODE: 34\n",
      "INITIAL REWARD: -129.716\n",
      "FINAL REWARD: -109.633\n",
      "#STEPS: 2 (2 RANDOM)\n",
      "EARLY STOPPING COUNT: 6/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -296.403\n",
      "MOVING AVG #STEPS: 5.0\n",
      "\n",
      "EPISODE: 35\n",
      "INITIAL REWARD: -388.38\n",
      "FINAL REWARD: -82.956\n",
      "#STEPS: 6 (6 RANDOM)\n",
      "EARLY STOPPING COUNT: 7/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -249.859\n",
      "MOVING AVG #STEPS: 4.9\n",
      "\n",
      "EPISODE: 36\n",
      "INITIAL REWARD: -147.379\n",
      "FINAL REWARD: -100.114\n",
      "#STEPS: 2 (2 RANDOM)\n",
      "EARLY STOPPING COUNT: 8/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -252.444\n",
      "MOVING AVG #STEPS: 5.0\n",
      "\n",
      "EPISODE: 37\n",
      "INITIAL REWARD: -158.358\n",
      "FINAL REWARD: -73.03\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 9/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -220.488\n",
      "MOVING AVG #STEPS: 4.7\n",
      "\n",
      "EPISODE: 38\n",
      "INITIAL REWARD: -263.338\n",
      "FINAL REWARD: -605.023\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -215.851\n",
      "MOVING AVG #STEPS: 4.7\n",
      "\n",
      "EPISODE: 39\n",
      "INITIAL REWARD: -401.028\n",
      "FINAL REWARD: -57.303\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -213.966\n",
      "MOVING AVG #STEPS: 4.6\n",
      "\n",
      "EPISODE: 40\n",
      "INITIAL REWARD: -151.993\n",
      "FINAL REWARD: -61.811\n",
      "#STEPS: 2 (2 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -214.941\n",
      "MOVING AVG #STEPS: 4.4\n",
      "\n",
      "EPISODE: 41\n",
      "INITIAL REWARD: -136.77\n",
      "FINAL REWARD: -815.53\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -238.639\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 42\n",
      "INITIAL REWARD: -283.589\n",
      "FINAL REWARD: -38.523\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -218.541\n",
      "MOVING AVG #STEPS: 4.3\n",
      "\n",
      "EPISODE: 43\n",
      "INITIAL REWARD: -381.778\n",
      "FINAL REWARD: -231.051\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -222.728\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 44\n",
      "INITIAL REWARD: -304.232\n",
      "FINAL REWARD: -85.182\n",
      "#STEPS: 5 (5 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -215.107\n",
      "MOVING AVG #STEPS: 4.4\n",
      "\n",
      "EPISODE: 45\n",
      "INITIAL REWARD: -208.307\n",
      "FINAL REWARD: -32.553\n",
      "#STEPS: 6 (6 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -215.579\n",
      "MOVING AVG #STEPS: 4.6\n",
      "\n",
      "EPISODE: 46\n",
      "INITIAL REWARD: -157.752\n",
      "FINAL REWARD: -18.505\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 3/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -215.816\n",
      "MOVING AVG #STEPS: 4.6\n",
      "\n",
      "EPISODE: 47\n",
      "INITIAL REWARD: -285.258\n",
      "FINAL REWARD: -7.378\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 4/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -199.062\n",
      "MOVING AVG #STEPS: 4.4\n",
      "\n",
      "EPISODE: 48\n",
      "INITIAL REWARD: -205.803\n",
      "FINAL REWARD: -101.925\n",
      "#STEPS: 4 (4 RANDOM)\n",
      "EARLY STOPPING COUNT: 5/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -200.22\n",
      "MOVING AVG #STEPS: 4.4\n",
      "\n",
      "EPISODE: 49\n",
      "INITIAL REWARD: -194.431\n",
      "FINAL REWARD: -174.889\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -185.767\n",
      "MOVING AVG #STEPS: 4.4\n",
      "\n",
      "EPISODE: 50\n",
      "INITIAL REWARD: -318.905\n",
      "FINAL REWARD: -738.111\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -205.326\n",
      "MOVING AVG #STEPS: 4.4\n",
      "\n",
      "EPISODE: 51\n",
      "INITIAL REWARD: -146.809\n",
      "FINAL REWARD: -53.598\n",
      "#STEPS: 2 (2 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -205.912\n",
      "MOVING AVG #STEPS: 4.4\n",
      "\n",
      "EPISODE: 52\n",
      "INITIAL REWARD: -274.355\n",
      "FINAL REWARD: -104.65\n",
      "#STEPS: 7 (7 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -205.738\n",
      "MOVING AVG #STEPS: 4.6\n",
      "\n",
      "EPISODE: 53\n",
      "INITIAL REWARD: -149.24\n",
      "FINAL REWARD: -549.163\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -221.165\n",
      "MOVING AVG #STEPS: 4.7\n",
      "\n",
      "EPISODE: 54\n",
      "INITIAL REWARD: -357.347\n",
      "FINAL REWARD: -102.247\n",
      "#STEPS: 4 (4 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -213.647\n",
      "MOVING AVG #STEPS: 4.6\n",
      "\n",
      "EPISODE: 55\n",
      "INITIAL REWARD: -145.313\n",
      "FINAL REWARD: -93.578\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -204.475\n",
      "MOVING AVG #STEPS: 4.3\n",
      "\n",
      "EPISODE: 56\n",
      "INITIAL REWARD: -247.056\n",
      "FINAL REWARD: -840.024\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -211.969\n",
      "MOVING AVG #STEPS: 4.3\n",
      "\n",
      "EPISODE: 57\n",
      "INITIAL REWARD: -181.044\n",
      "FINAL REWARD: -1163.204\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -248.357\n",
      "MOVING AVG #STEPS: 4.4\n",
      "\n",
      "EPISODE: 58\n",
      "INITIAL REWARD: -223.924\n",
      "FINAL REWARD: -69.138\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -223.717\n",
      "MOVING AVG #STEPS: 4.2\n",
      "\n",
      "EPISODE: 59\n",
      "INITIAL REWARD: -159.788\n",
      "FINAL REWARD: -24.642\n",
      "#STEPS: 2 (2 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -222.233\n",
      "MOVING AVG #STEPS: 4.2\n",
      "\n",
      "EPISODE: 60\n",
      "INITIAL REWARD: -201.62\n",
      "FINAL REWARD: -52.195\n",
      "#STEPS: 4 (4 RANDOM)\n",
      "EARLY STOPPING COUNT: 3/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -222.034\n",
      "MOVING AVG #STEPS: 4.2\n",
      "\n",
      "EPISODE: 61\n",
      "INITIAL REWARD: -283.024\n",
      "FINAL REWARD: -442.115\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -232.926\n",
      "MOVING AVG #STEPS: 4.4\n",
      "\n",
      "EPISODE: 62\n",
      "INITIAL REWARD: -151.775\n",
      "FINAL REWARD: -87.479\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -232.269\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 63\n",
      "INITIAL REWARD: -202.671\n",
      "FINAL REWARD: -382.022\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -243.252\n",
      "MOVING AVG #STEPS: 4.7\n",
      "\n",
      "EPISODE: 64\n",
      "INITIAL REWARD: -183.103\n",
      "FINAL REWARD: -73.441\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -242.046\n",
      "MOVING AVG #STEPS: 4.7\n",
      "\n",
      "EPISODE: 65\n",
      "INITIAL REWARD: -203.888\n",
      "FINAL REWARD: -38.471\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -240.563\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 66\n",
      "INITIAL REWARD: -125.036\n",
      "FINAL REWARD: -284.865\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -246.722\n",
      "MOVING AVG #STEPS: 4.7\n",
      "\n",
      "EPISODE: 67\n",
      "INITIAL REWARD: -427.318\n",
      "FINAL REWARD: -66.569\n",
      "#STEPS: 3 (3 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -246.506\n",
      "MOVING AVG #STEPS: 4.8\n",
      "\n",
      "EPISODE: 68\n",
      "INITIAL REWARD: -227.27\n",
      "FINAL REWARD: -624.666\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -247.161\n",
      "MOVING AVG #STEPS: 4.8\n",
      "\n",
      "EPISODE: 69\n",
      "INITIAL REWARD: -146.468\n",
      "FINAL REWARD: -68.752\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -247.543\n",
      "MOVING AVG #STEPS: 4.8\n",
      "\n",
      "EPISODE: 70\n",
      "INITIAL REWARD: -201.723\n",
      "FINAL REWARD: -46.05\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -247.017\n",
      "MOVING AVG #STEPS: 4.7\n",
      "\n",
      "EPISODE: 71\n",
      "INITIAL REWARD: -284.357\n",
      "FINAL REWARD: -105.87\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 3/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -223.362\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 72\n",
      "INITIAL REWARD: -202.414\n",
      "FINAL REWARD: -94.783\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 4/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -225.237\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 73\n",
      "INITIAL REWARD: -218.325\n",
      "FINAL REWARD: -782.39\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -243.615\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 74\n",
      "INITIAL REWARD: -300.473\n",
      "FINAL REWARD: -83.656\n",
      "#STEPS: 5 (5 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -243.564\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 75\n",
      "INITIAL REWARD: -287.2\n",
      "FINAL REWARD: -70.212\n",
      "#STEPS: 3 (3 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -244.82\n",
      "MOVING AVG #STEPS: 4.4\n",
      "\n",
      "EPISODE: 76\n",
      "INITIAL REWARD: -248.254\n",
      "FINAL REWARD: -49.948\n",
      "#STEPS: 4 (4 RANDOM)\n",
      "EARLY STOPPING COUNT: 3/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -245.868\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 77\n",
      "INITIAL REWARD: -249.096\n",
      "FINAL REWARD: -52.435\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 4/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -247.37\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 78\n",
      "INITIAL REWARD: -190.474\n",
      "FINAL REWARD: -47.398\n",
      "#STEPS: 4 (4 RANDOM)\n",
      "EARLY STOPPING COUNT: 5/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -245.552\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 79\n",
      "INITIAL REWARD: -169.513\n",
      "FINAL REWARD: -352.071\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -251.458\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 80\n",
      "INITIAL REWARD: -127.64\n",
      "FINAL REWARD: -108.557\n",
      "#STEPS: 1 (1 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -230.473\n",
      "MOVING AVG #STEPS: 4.3\n",
      "\n",
      "EPISODE: 81\n",
      "INITIAL REWARD: -143.742\n",
      "FINAL REWARD: -489.912\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -245.017\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 82\n",
      "INITIAL REWARD: -174.227\n",
      "FINAL REWARD: -356.978\n",
      "#STEPS: 8 (8 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -253.428\n",
      "MOVING AVG #STEPS: 4.5\n",
      "\n",
      "EPISODE: 83\n",
      "INITIAL REWARD: -220.097\n",
      "FINAL REWARD: -89.569\n",
      "#STEPS: 3 (3 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -238.108\n",
      "MOVING AVG #STEPS: 4.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "EPISODE: 84\n",
      "INITIAL REWARD: -131.46\n",
      "FINAL REWARD: -417.547\n",
      "#STEPS: 8 (5 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -248.618\n",
      "MOVING AVG #STEPS: 4.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 85:   0%|                                                  | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/Desktop/orig/qbm-rl-steering/qbm_rl_steering/core/ddpg_agents.py:496: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_weights = np.array(self.target_actor_net.get_weights())\n",
      "/Users/michael/Desktop/orig/qbm-rl-steering/qbm_rl_steering/core/ddpg_agents.py:497: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  main_weights = np.array(self.main_actor_net.get_weights())\n",
      "\r",
      "Learning progress -- Episode 85:  12%|████▊                                 | 1/8 [34:51<4:03:59, 2091.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 85, stp 0\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 85:  25%|█████████                           | 2/8 [1:06:31<3:17:54, 1979.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 85, stp 1\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 85:  38%|█████████████▌                      | 3/8 [1:43:44<2:54:34, 2094.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 85, stp 2\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 85:  50%|██████████████████                  | 4/8 [2:24:02<2:28:08, 2222.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 85, stp 3\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 85:  62%|██████████████████████▌             | 5/8 [2:59:25<1:49:19, 2186.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 85, stp 4\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 85:  75%|███████████████████████████         | 6/8 [3:36:47<1:13:31, 2205.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 85, stp 5\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 85:  88%|█████████████████████████████████▎    | 7/8 [4:11:48<36:11, 2171.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 85, stp 6\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 85: 100%|██████████████████████████████████████| 8/8 [4:48:07<00:00, 2160.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 85, stp 7\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "\n",
      "EPISODE: 85\n",
      "INITIAL REWARD: -178.443\n",
      "FINAL REWARD: -189.665\n",
      "#STEPS: 8 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -251.821\n",
      "MOVING AVG #STEPS: 4.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 86:   0%|                                                  | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 86:  12%|████▊                                 | 1/8 [39:32<4:36:46, 2372.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 86, stp 0\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 86:  25%|█████████                           | 2/8 [1:20:04<4:00:44, 2407.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 86, stp 1\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 86:  38%|█████████████▌                      | 3/8 [1:57:59<3:15:35, 2347.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 86, stp 2\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 86:  50%|██████████████████                  | 4/8 [2:38:08<2:38:05, 2371.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 86, stp 3\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 86:  62%|██████████████████████▌             | 5/8 [3:14:36<1:55:16, 2305.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 86, stp 4\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 86:  75%|███████████████████████████         | 6/8 [3:57:28<1:19:51, 2395.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 86, stp 5\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 86:  88%|█████████████████████████████████▎    | 7/8 [4:38:18<40:13, 2413.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 86, stp 6\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 86: 100%|██████████████████████████████████████| 8/8 [5:15:13<00:00, 2364.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 86, stp 7\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "EPISODE: 86\n",
      "INITIAL REWARD: -214.786\n",
      "FINAL REWARD: -132.28\n",
      "#STEPS: 8 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -228.229\n",
      "MOVING AVG #STEPS: 4.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 87:   0%|                                                  | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 87:  12%|████▊                                 | 1/8 [31:38<3:41:28, 1898.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 87, stp 0\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 87:  25%|█████████                           | 2/8 [1:09:22<3:31:20, 2113.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 87, stp 1\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 87:  38%|█████████████▌                      | 3/8 [1:44:41<2:56:20, 2116.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 87, stp 2\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 87:  50%|██████████████████                  | 4/8 [2:22:55<2:25:44, 2186.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 87, stp 3\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 87:  62%|██████████████████████▌             | 5/8 [3:04:30<1:54:52, 2297.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 87, stp 4\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 87:  75%|███████████████████████████         | 6/8 [3:39:57<1:14:39, 2239.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 87, stp 5\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 87:  88%|█████████████████████████████████▎    | 7/8 [4:18:41<37:47, 2267.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 87, stp 6\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 87: 100%|██████████████████████████████████████| 8/8 [4:56:46<00:00, 2225.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 87, stp 7\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE: 87\n",
      "INITIAL REWARD: -142.091\n",
      "FINAL REWARD: -108.727\n",
      "#STEPS: 1 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -193.08\n",
      "MOVING AVG #STEPS: 4.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 88:   0%|                                                  | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 88: 100%|████████████████████████████████████████| 1/1 [35:55<00:00, 2155.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 88, stp 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE: 88\n",
      "INITIAL REWARD: -256.719\n",
      "FINAL REWARD: -114.76\n",
      "#STEPS: 6 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -194.601\n",
      "MOVING AVG #STEPS: 4.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 89:   0%|                                                  | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 89:  17%|██████▎                               | 1/6 [46:10<3:50:50, 2770.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 89, stp 0\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 89:  33%|████████████                        | 2/6 [1:28:24<2:55:25, 2631.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 89, stp 1\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 89:  50%|██████████████████                  | 3/6 [2:01:29<1:56:48, 2336.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 89, stp 2\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 89:  67%|████████████████████████            | 4/6 [2:36:17<1:14:36, 2238.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 89, stp 3\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 89:  83%|███████████████████████████████▋      | 5/6 [3:18:38<39:07, 2347.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 89, stp 4\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 89: 100%|██████████████████████████████████████| 6/6 [3:57:00<00:00, 2370.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 89, stp 5\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE: 89\n",
      "INITIAL REWARD: -192.893\n",
      "FINAL REWARD: -95.907\n",
      "#STEPS: 2 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -196.976\n",
      "MOVING AVG #STEPS: 4.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 90:   0%|                                                  | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 90:  50%|████████████████████                    | 1/2 [36:49<36:49, 2209.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 90, stp 0\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 90: 100%|██████████████████████████████████████| 2/2 [1:09:13<00:00, 2076.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 90, stp 1\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE: 90\n",
      "INITIAL REWARD: -190.584\n",
      "FINAL REWARD: -88.187\n",
      "#STEPS: 3 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 0/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -198.176\n",
      "MOVING AVG #STEPS: 4.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 91:   0%|                                                  | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 91:  33%|████████████▋                         | 1/3 [36:06<1:12:12, 2166.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 91, stp 0\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 91:  67%|█████████████████████████▎            | 2/3 [1:11:40<35:47, 2147.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 91, stp 1\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=9, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /sapi/v2/problems/?id=fbbb0d85-00b2-49b1-9147-ab3d853598eb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=9, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /sapi/v2/problems/?id=7598b1f2-1dd1-44ef-ad97-c09c96ebc99b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 91: 100%|██████████████████████████████████████| 3/3 [1:44:25<00:00, 2088.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 91, stp 2\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE: 91\n",
      "INITIAL REWARD: -153.541\n",
      "FINAL REWARD: -116.033\n",
      "#STEPS: 1 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 1/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -187.307\n",
      "MOVING AVG #STEPS: 4.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 92:   0%|                                                  | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 92: 100%|████████████████████████████████████████| 1/1 [34:19<00:00, 2059.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 92, stp 0\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE: 92\n",
      "INITIAL REWARD: -129.855\n",
      "FINAL REWARD: -80.411\n",
      "#STEPS: 1 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 2/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -187.071\n",
      "MOVING AVG #STEPS: 4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 93:   0%|                                                  | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 93: 100%|████████████████████████████████████████| 1/1 [34:03<00:00, 2043.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 93, stp 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE: 93\n",
      "INITIAL REWARD: -186.41\n",
      "FINAL REWARD: -110.713\n",
      "#STEPS: 2 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 3/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -178.027\n",
      "MOVING AVG #STEPS: 3.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 94:   0%|                                                  | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "SAVING EVERYTHING: Ep 94, stp 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 94:  50%|████████████████████                    | 1/2 [30:32<30:32, 1832.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 94: 100%|██████████████████████████████████████| 2/2 [1:02:25<00:00, 1872.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 94, stp 1\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE: 94\n",
      "INITIAL REWARD: -280.983\n",
      "FINAL REWARD: -108.4\n",
      "#STEPS: 2 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 4/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -179.193\n",
      "MOVING AVG #STEPS: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 95:   0%|                                                  | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 95:  50%|████████████████████                    | 1/2 [31:26<31:26, 1886.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 95, stp 0\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 95: 100%|██████████████████████████████████████| 2/2 [1:03:35<00:00, 1907.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 95, stp 1\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE: 95\n",
      "INITIAL REWARD: -159.286\n",
      "FINAL REWARD: -92.502\n",
      "#STEPS: 1 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 5/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -180.994\n",
      "MOVING AVG #STEPS: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 96:   0%|                                                  | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 96: 100%|████████████████████████████████████████| 1/1 [32:56<00:00, 1976.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 96, stp 0\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE: 96\n",
      "INITIAL REWARD: -129.079\n",
      "FINAL REWARD: -66.687\n",
      "#STEPS: 1 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 6/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -173.721\n",
      "MOVING AVG #STEPS: 3.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 97:   0%|                                                  | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 97: 100%|████████████████████████████████████████| 1/1 [32:53<00:00, 1973.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 97, stp 0\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE: 97\n",
      "INITIAL REWARD: -222.057\n",
      "FINAL REWARD: -102.037\n",
      "#STEPS: 2 (0 RANDOM)\n",
      "EARLY STOPPING COUNT: 7/20000\n",
      "\n",
      "MOVING AVG FINAL REWARD: -174.903\n",
      "MOVING AVG #STEPS: 3.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 98:   0%|                                                  | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Learning progress -- Episode 98:  50%|████████████████████                    | 1/2 [27:43<27:43, 1663.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 98, stp 0\n",
      "Calling main_critic to calculate q values on batch in get_analytical_action_derivative ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n",
      "Looping over batch of samples, getting current and future Q values in _update_critic ...\n",
      "Sample in batch: 1/16\n",
      "Sample in batch: 5/16\n",
      "Sample in batch: 9/16\n",
      "Sample in batch: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning progress -- Episode 98: 100%|████████████████████████████████████████| 2/2 [57:54<00:00, 1737.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING EVERYTHING: Ep 98, stp 1\n",
      "n_total_steps_training 441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(out_path + '/params_dict.pkl', 'wb') as fid:\n",
    "    pickle.dump(params, fid)\n",
    "\n",
    "# AGENT TRAINING\n",
    "episode_log = trainer(\n",
    "    env=env, agent=agentMy, action_noise_schedule=action_noise_schedule,\n",
    "    epsilon_greedy_schedule=epsilon_greedy_schedule,\n",
    "    n_anneals_schedule=n_anneals_schedule, n_steps=params['n_steps'],\n",
    "    max_steps_per_episode=params['env/max_steps_per_episode'],\n",
    "    batch_size=params['trainer/batch_size'],\n",
    "    n_exploration_steps=params['trainer/n_exploration_steps'],\n",
    "    n_episodes_early_stopping=params['trainer/n_episodes_early_stopping'],\n",
    "    out_path=out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_log(env, agentMy, episode_log, apply_scaling=True,\n",
    "                  save_path=out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_training_episodes = len(episode_log['final_rewards'])\n",
    "episode_log_2 = {}\n",
    "for k, v in episode_log.items():\n",
    "    if len(v) != 0:\n",
    "        episode_log_2[k] = v[:]\n",
    "episode_log = episode_log_2\n",
    "\n",
    "df_train_log = pd.DataFrame(episode_log)\n",
    "df_train_log.to_csv(out_path + '/train_log')\n",
    "\n",
    "# Save agent\n",
    "weights = {\n",
    "    'main_critic': {\n",
    "        'w_vh': agentMy.main_critic_net.w_vh,\n",
    "        'w_hh': agentMy.main_critic_net.w_hh},\n",
    "    'target_critic': {\n",
    "        'w_vh': agentMy.target_critic_net.w_vh,\n",
    "        'w_hh': agentMy.target_critic_net.w_hh}}\n",
    "\n",
    "with open(out_path + '/critic_weights.pkl', 'wb') as fid:\n",
    "    pickle.dump(weights, fid)\n",
    "\n",
    "weights = {'main_actor': agentMy.main_actor_net.get_weights(),\n",
    "           'target_actor': agentMy.target_actor_net.get_weights()}\n",
    "with open(out_path + '/actor_weights.pkl', 'wb') as fid:\n",
    "    pickle.dump(weights, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception ...\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "env = e_trajectory_simENV()\n",
    "eval_log_scan = evaluator(env, agentMy, n_episodes=50, reward_scan=False)\n",
    "np.save(out_path + '/eval_log_scan.npy', eval_log_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evaluation_log(\n",
    "    env, env.MAX_TIME+1, eval_log_scan, type='random', apply_scaling=True,\n",
    "    save_path=out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
